{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Skill Check 10\n",
    "\n",
    "The block below imports the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "In this assignment, you will work with the Dow dataset you have handled a few weeks ago. Reading and cleaning the dataset is done in the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('impurity_dataset-training.xlsx')\n",
    "\n",
    "def is_real_and_finite(x):\n",
    "    if not np.isreal(x):\n",
    "        return False\n",
    "    elif not np.isfinite(x):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "all_data = df[df.columns[1:]].values\n",
    "numeric_map = df[df.columns[1:]].applymap(is_real_and_finite)\n",
    "real_rows = numeric_map.all(axis = 1).copy().values\n",
    "X_dow = np.array(all_data[real_rows, :-5], dtype = 'float')\n",
    "y_dow = np.array(all_data[real_rows, -3], dtype = 'float')\n",
    "y = y_dow.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 1. k-Means (35 pts)\n",
    "\n",
    "The k-means algorithm is an iterative type of algorithm that pursues the following expectation-maximization:\n",
    "\n",
    "- **Expectation**: expect that the points close to the center of a cluster belong to that cluster\n",
    "- **Maximization**: maximize the proximity of points to the center of a cluster by moving the center\n",
    "\n",
    "In this problem, you will implement the k-means algorithm with several functions provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def dist(pt1, pt2):\n",
    "    return np.sqrt(sum([(xi - yi)**2 for xi, yi in zip(pt1, pt2)]))\n",
    "\n",
    "def expected_assignment(pt, cluster_centers):\n",
    "    dists = [dist(pt, ci) for ci in cluster_centers]\n",
    "    min_index = dists.index(min(dists))\n",
    "    return min_index\n",
    "\n",
    "def new_centers(cluster_points, centers):\n",
    "    centers = list(centers)\n",
    "    for i, ci in enumerate(cluster_points):\n",
    "        if ci != []:\n",
    "            centers[i] = np.mean(ci, axis = 0)\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 1a: Data Preparation (15 pts)\n",
    "\n",
    "First, you need a preprocessing step to transform the given Dow dataset. Obtain a matrix named `X` as a result of the following steps:\n",
    "\n",
    "- Standardize `X_dow` using the \"standard scaler\"\n",
    "- Project the standardized `X_dow` onto 2-dimensional space using PCA\n",
    "- Take every 5th data point\n",
    "\n",
    "The resulting matrix should be stored as `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(X_dow)\n",
    "X_pca = PCA(n_components = 2).fit_transform(X_scaled)\n",
    "X = X_pca[::5]\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-1",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert X.shape[1] == 2, \"projection onto the wrong dimension\"\n",
    "assert X.shape[0] == 2060, \"wrong data size\"\n",
    "assert np.isclose(X[:, 0].sum(), 20.5537312894985)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 1b: One iteration of k-means (10 pts)\n",
    "\n",
    "Making use of the functions defined above, apply the k-means algorithm **once** to the dataset and report the resulting new cluster centers in the variable `new_cluster_centers`. The initial guesses are provided below as `old_cluster_centers`, and you should keep the same data structure (e.g. a list of lists) as `new_cluster_centers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "old_cluster_centers = ([0, 0], [2, 2], [30, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "old_centers = np.array(old_cluster_centers)\n",
    "\n",
    "clusters = []\n",
    "for i in range(old_centers.shape[0]):\n",
    "    clusters.append([])\n",
    "    \n",
    "for pt in X:\n",
    "    cluster_idx = expected_assignment(pt, old_centers)\n",
    "    clusters[cluster_idx].append(pt)\n",
    "    \n",
    "new_cluster_centers = new_centers(clusters, old_centers)\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-2",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(np.array(new_cluster_centers).sum(axis = 0)[0], 29.21008259)\n",
    "assert np.isclose(np.array(new_cluster_centers).mean(axis = 1)[1], 2.22463995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 1c: Convergence of k-means (10 pts)\n",
    "\n",
    "In this problem, you will define a function `kmeans` that implements the k-means alogrithm until the pre-defined convergence criterion is satistified. The `kmeans` function takes the following arguments:\n",
    "\n",
    "- `X`: dataset (numpy array)\n",
    "- `centers`: initial guesses for cluster centers (numpy array)\n",
    "- `tol`: convergence tolerance (float, default = 0.1)\n",
    "\n",
    "Note that the number of clusters will be implicitly defined by the number of rows in the `centers` array.\n",
    "\n",
    "**Convergence criterion**: the maximum change in distance between cluster centers < `tol`.\n",
    "\n",
    "Your `kmeans` function should return `new_center` (numpy array) and `clusters` (list of lists with the indices of the points in each cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans(X, centers, tol = 0.1):\n",
    "########################################\n",
    "# Start your code here\n",
    "    old_center = np.array(centers)\n",
    "    max_dist = 1e6\n",
    "    \n",
    "    while max_dist > tol:\n",
    "        clusters = []\n",
    "        for i in range(old_center.shape[0]):\n",
    "            clusters.append([])\n",
    "            \n",
    "        for pt in X:\n",
    "            cluster_idx = expected_assignment(pt, old_center)\n",
    "            clusters[cluster_idx].append(pt)\n",
    "            \n",
    "        new_center = new_centers(clusters, old_center)\n",
    "        \n",
    "        max_dist = 0\n",
    "        for i in range(old_center.shape[0]):\n",
    "            dist = np.linalg.norm(old_center[i] - new_center[i])\n",
    "            if max_dist < dist:\n",
    "                max_dist = dist\n",
    "                \n",
    "        old_center = np.array(new_center)\n",
    "########################################\n",
    "    return np.array(new_center), clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-3",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "centers, clusters = kmeans(X, np.array(old_cluster_centers))\n",
    "\n",
    "assert type(centers) == np.ndarray, \"wrong data type for centers\"\n",
    "assert type(clusters) == list, \"wrong data type for clusters\"\n",
    "assert np.isclose(centers.mean(axis = 1)[2], 13.04660452), \"wrong cluster centers\"\n",
    "assert len(clusters[0]) == 1403, \"wrong clusters\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 2. Mean Shift (35 pts)\n",
    "\n",
    "The mean shift algorithm is also an iterative type of algorithm, but unlike the k-means, it is density-based rather than expectation-maximization based. You may find the functions defined below useful through this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_distance(x1, x2):\n",
    "    return np.linalg.norm(x1 - x2, 2)\n",
    "\n",
    "def get_nearby_points(x, x_list, bandwidth):\n",
    "    dist_pairs = []\n",
    "    for i, xi in enumerate(x_list):\n",
    "        dist = get_distance(x, xi)\n",
    "        dist_pairs.append([dist, i, xi])\n",
    "    in_window = [pt[-1] for pt in dist_pairs if pt[0] <= bandwidth]\n",
    "    return in_window\n",
    "\n",
    "def get_new_centroid(old_centroid, x_list, bandwidth):\n",
    "    in_range = get_nearby_points(old_centroid, x_list, bandwidth)\n",
    "    if len(in_range) == 0:\n",
    "        new_centroid = old_centroid\n",
    "    else:\n",
    "        new_centroid = np.array(in_range).mean(axis = 0)\n",
    "    return new_centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 2a: One iteration of mean shift (15 pts)\n",
    "\n",
    "Take `old_cluster_centers` (defined in Problem 1) as intial guesses for centroids and find a new centroids `new_centroids` using a `bandwith` of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "new_centroids = []\n",
    "for c in old_cluster_centers:\n",
    "    new_centroids.append(get_new_centroid(c, X, 5))\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": " p2-1",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(np.array(new_centroids).sum(axis = 0)[0], 29.43546375)\n",
    "assert np.isclose(np.linalg.norm(new_centroids), 30.992548441545583)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 2b: Converging mean shift (20 pts)\n",
    "\n",
    "A typical convergence criterion for the mean shift algorithm is checking whether old centroids and new centroids are identical to each other. Report the final centroids `final_centroids` after convergence (15 pts) and the number of iterations needed to reach convergence `num_iter` (5 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "delta = 1\n",
    "old_centroids = old_cluster_centers\n",
    "\n",
    "while delta > 0:\n",
    "    new_centroids = []\n",
    "    for c in old_centroids:\n",
    "        new_centroids.append(get_new_centroid(c, X, 5))\n",
    "        \n",
    "    delta = 0\n",
    "    for i, c in enumerate(old_centroids):\n",
    "        if delta < get_distance(c, new_centroids[i]):\n",
    "            delta = 1\n",
    "            \n",
    "    old_centroids = new_centroids\n",
    "    \n",
    "final_centroids = new_centroids\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": " p2-2-1",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(np.array(final_centroids).sum(), 24.840886688211803)\n",
    "assert np.isclose((final_centroids[1] - final_centroids[2])[0], -31.595831127643677)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p2-2-2",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.array(old_cluster_centers * 4).sum(axis = 0)[0] == 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 3. Gaussian Mixture Models (30 pts)\n",
    "\n",
    "The Gaussian Mixture Models (GMM) is a generative algorithm based on expectation-maximization. In this problem, you will play with the built-in `sklearn.mixture.GaussainMixture` object.\n",
    "\n",
    "### 3a: Import the object (10 pts)\n",
    "\n",
    "Import the `sklearn.mixture.GaussianMixture` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "from sklearn.mixture import GaussianMixture\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p3-1",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert GaussianMixture.__init__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 3b: Silhouette score and Calinski-Harabasz score (10 pts)\n",
    "\n",
    "Apply the GMM to `X` with the following settings and report the resulting silhouette score `sil_score` and Calinski-Harabasz score `ch_score`.\n",
    "\n",
    "- `n_components`: 4\n",
    "- `random_state`: 42\n",
    "- `covariance_type`: `tied`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "gmm = GaussianMixture(n_components = 4, random_state = 42, covariance_type = 'tied')\n",
    "gmm.fit(X)\n",
    "y_predict = gmm.predict(X)\n",
    "\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "\n",
    "sil_score = silhouette_score(X, y_predict)\n",
    "ch_score = calinski_harabasz_score(X, y_predict)\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p3-2",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(sil_score * ch_score, 5086.217116738762)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c: Mixed membership (10 pts)\n",
    "\n",
    "GMM supports mixed membership, so points have probabilites of belonging to all clusters. Find the cluster that has the second highest of probability for 101st data point in `X` (i.e. the point indexed by 100). Save the cluster label to `sec_high_cluster` and the corresponding probabiltiy `sec_high_prob`. You should assume that clusters are labeled as 1-4 (i.e. there is no cluster 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "prob = gmm.predict_proba(X)[100, :]\n",
    "prob_copy = prob.copy()\n",
    "\n",
    "prob.sort()\n",
    "sec_high_prob = prob[-2]\n",
    "sec_high_cluster = np.where(prob_copy == sec_high_prob)[0] + 1\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p3-3",
     "locked": true,
     "points": "10",
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert np.isclose(sec_high_prob * sec_high_cluster, 0.005392117243474652)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.7]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
