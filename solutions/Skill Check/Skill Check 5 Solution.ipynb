{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Skill Check 5\n",
    "\n",
    "The block below imports the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 0. The Dow Dataset (5 pts)\n",
    "\n",
    "You will work on the new dataset, which is the Dow dataset, from this week. Read in the `impurity_dataset-training.xlsx` as a `pandas.DataFrame` with a variable name `df`. (5 pts)\n",
    "\n",
    "Note: If you run this on a computer without Microsoft Excel you may get an error. However, it should work reliably in the Vocareum environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "df = pd.read_excel('impurity_dataset-training.xlsx')\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p0",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(df) == pd.core.frame.DataFrame\n",
    "assert df.shape == (10703, 46)\n",
    "assert np.isclose(np.linalg.norm(df[df.columns[1:]].loc[1]), 3381.2181210675867)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The cell below will clean the `df` to remove invalid cells and missing values. This cell create two variables `X` and `y` that will be the input feature matrix and corresponding impurity concentrations, respectively. You don't need to understand how this works yet, but we will cover it in future lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def is_real_and_finite(x):\n",
    "    if not np.isreal(x):\n",
    "        return False\n",
    "    elif not np.isfinite(x):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "all_data = df[df.columns[1:]].values #drop the first column (date)\n",
    "numeric_map = df[df.columns[1:]].applymap(is_real_and_finite)\n",
    "real_rows = numeric_map.all(axis=1).copy().values #True if all values in a row are real numbers\n",
    "X = np.array(all_data[real_rows,:-5], dtype='float') #drop the last 5 cols that are not inputs\n",
    "y = np.array(all_data[real_rows,-3], dtype='float')\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 1. Feature Scaling (75 pts)\n",
    "\n",
    "In this problem, you will see how feature scaling will affect the model performance. First, import `StandardScaler` and `MinMaxScaler` from `scikit-learn`. Declare a `StandardScaler` object `ss` and a `MinMaxScaler` object `mms`. Do not change any default parameter settings for both scaler objects. (15 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "mms = MinMaxScaler()\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-1",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(ss) == sklearn.preprocessing._data.StandardScaler\n",
    "assert type(mms) == sklearn.preprocessing._data.MinMaxScaler\n",
    "\n",
    "assert ss.with_mean and ss.with_std, \"default setting for StandardScaler changed\"\n",
    "assert mms.feature_range == (0, 1), \"default setting for MinMaxScaler changed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Train a LASSO model with the Dow dataset and find the best scaling method (among no scaling, standard scaling, and min-max scaling). Below is the instruction step by step.\n",
    "\n",
    "- Do train/test split on `X` and `y` by `train_test_split` with `test_size=0.3` and `random_state=42`. The training set and test set should be named as `*_train` and `*_test` where `*` denotes either `X` or `y`, respectively. (20 pts)\n",
    "- Declare a LASSO model with `alpha=1e-4` and `tol=0.15`. Assign the LASSO model to the variable `lasso`. (10 points)\n",
    "- For each scaling method, train the LASSO model on the training set and provide the $\\mathrm{r^2}$ for the test set.\n",
    "- Report the best $\\mathrm{r^2}$ as `r2_opt`. (20 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "########################################\n",
    "# Start your code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "lasso = Lasso(alpha = 1e-4, tol = 0.15)\n",
    "\n",
    "X_train_ss = ss.fit_transform(X_train)\n",
    "X_test_ss = ss.transform(X_test)\n",
    "\n",
    "X_train_mms = mms.fit_transform(X_train)\n",
    "X_test_mms = mms.transform(X_test)\n",
    "\n",
    "train = [X_train, X_train_ss, X_train_mms]\n",
    "test = [X_test, X_test_ss, X_test_mms]\n",
    "\n",
    "r2_opt = 0\n",
    "for tr, te in zip(train, test):\n",
    "    lasso.fit(tr, y_train)\n",
    "    if r2_opt < lasso.score(te, y_test):\n",
    "        r2_opt = lasso.score(te, y_test)\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-2",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert X_train.shape == (7207, 40), \"test_size not correct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-3",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(np.linalg.norm(X_test), 229401.15359462335), \"random_state not correct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-4",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(lasso) == sklearn.linear_model._coordinate_descent.Lasso, \"LASSO model not stored to correct variable\"\n",
    "assert lasso.alpha == 1e-4, \"Alpha parameter of LASSO is not correct\"\n",
    "assert lasso.tol == 0.15, \"Tolerance not correct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-5",
     "locked": true,
     "points": "20",
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert np.isclose(r2_opt, 0.6805049793263493), \"r2 not correct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Report the resulting parameter vector after all features with a coefficient of zero have been dropped in the case of **min-max scaling**. The name of the reduced parameter vector should `dropped_coefs`. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "lasso.fit(X_train_mms, y_train)\n",
    "coefs = lasso.coef_\n",
    "\n",
    "dropped_coefs = coefs[coefs != 0]\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-6",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(np.linalg.norm(dropped_coefs) * len(dropped_coefs), 495.69726745190184), \"parameter vector not correct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 2. Principal Component Analysis (20 pts)\n",
    "\n",
    "Principal component analysis is closely related to the eigenvalue decomposition of the correlation matrix, as described in the lectures. This problem ensures that you know how to obtain the principal components in this way.\n",
    "\n",
    "First, create a correlation matrix `corr` from `X`. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "corr = np.corrcoef(X.T)\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p2-1",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(np.linalg.norm(corr), 24.09288033850843)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Next, get the eigenvectors and corresponding eigenvalues for the correlation matrix. Report the third highest eigenvalue as `eig_3` and the eigenvector corresponding to the sixth highest eigenvalue as `eigvec_6`. (10 pts)\n",
    "\n",
    "Hint: Remember that eigenvectors are stored as columns by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import eig\n",
    "\n",
    "########################################\n",
    "# Start your code here\n",
    "eigvals, eigvecs = eig(corr)\n",
    "\n",
    "eig_3 = eigvals[2]\n",
    "eigvec_6 = eigvecs[:, 5]\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p2-2",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(np.real(eig_3), 2.33189496669), \"Eigenvalue is not correct\"\n",
    "assert np.isclose(eigvec_6[0], 0.13732149628), \"Eigenvector is not correct\"\n",
    "assert np.isclose(np.real(eig_3) * np.linalg.norm(eigvec_6[:10]), 0.8256564069966813), \"Incorrect eigenvalue or eigenvector selected\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.7]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
