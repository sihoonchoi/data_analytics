{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Skill Check 11\n",
    "\n",
    "The block below imports necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "In this assignment, you will work with the Dow dataset and MNIST dataset. Both datasets are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Dow Dataset\n",
    "df = pd.read_excel('impurity_dataset-training.xlsx')\n",
    "\n",
    "def is_real_and_finite(x):\n",
    "    if not np.isreal(x):\n",
    "        return False\n",
    "    elif not np.isfinite(x):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "all_data = df[df.columns[1:]].values\n",
    "numeric_map = df[df.columns[1:]].applymap(is_real_and_finite)\n",
    "real_rows = numeric_map.all(axis = 1).copy().values\n",
    "X_dow = np.array(all_data[real_rows, :-5], dtype = 'float')\n",
    "y_dow = np.array(all_data[real_rows, -3], dtype = 'float')\n",
    "y = y_dow.reshape(-1, 1)\n",
    "\n",
    "# MNIST Dataset\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X_mnist = np.array(digits.data)\n",
    "y_mnist = np.array(digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 1. Partial Least Squares (50 pts)\n",
    "\n",
    "Partial least squares regression (PLS regression) is a supervised algorithm that finds **linear** combinations of features that maximize the covariance between features.\n",
    "\n",
    "### 1a: Import `PLSRegression` (10 pts)\n",
    "\n",
    "Import the `sklearn.cross_decomposition.PLSRegression` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-1",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert PLSRegression.__init__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 1b: Standardization (10 pts)\n",
    "\n",
    "Standardize `X_dow` and save the resulting matrix to `X_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(X_dow)\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-2",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(X_scaled.mean(axis = 0), 0).all()\n",
    "assert np.isclose(X_scaled.std(axis = 0), 1).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 1c: PLS Regression (10 pts)\n",
    "\n",
    "Declare a `PLSRegression` object `pls` with `n_components = 5`. Train `pls` with `X_scaled` and `y`. Report the $\\mathrm{r^2}$ as `pls_r2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "pls = PLSRegression(n_components = 5)\n",
    "pls.fit(X_scaled, y)\n",
    "pls_r2 = pls.score(X_scaled, y)\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-3",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert pls.n_components == 5\n",
    "assert np.isclose(pls_r2, 0.6533602447390862)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 1d: Achieving $\\mathrm{r^2}$ of 0.68 (15 pts)\n",
    "\n",
    "Find the minimum `n_components` with which $\\mathrm{r^2}$ is above 0.68 when `PLSRegression` is trained and tested on `X_scaled` and `y`. Report the number as `min_n_comp` and the corresponding $\\mathrm{r^2}$ as `r2_n_comp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "n = 1\n",
    "r2 = 0\n",
    "\n",
    "while r2 < 0.68:\n",
    "    n += 1\n",
    "    \n",
    "    pls = PLSRegression(n_components = n)\n",
    "    pls.fit(X_scaled, y)\n",
    "    r2 = pls.score(X_scaled, y)\n",
    "    \n",
    "min_n_comp = n\n",
    "r2_n_comp = r2\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-4",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(min_n_comp * r2_n_comp, 5.455616652135625)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 1e: Feature transformation (5 pts)\n",
    "\n",
    "Transform the features and reduce the dimensionality to `min_n_comp`. Name the matrix of transformed features `X_pls`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "pls = PLSRegression(n_components = min_n_comp)\n",
    "pls.fit(X_scaled, y)\n",
    "\n",
    "X_pls = pls.transform(X_scaled)\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p1-5",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert X_pls.shape[0] == 10297\n",
    "assert X_pls.shape[1] == min_n_comp\n",
    "assert np.isclose(np.linalg.norm(X_pls), 537.5375896752992)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 2. Linear Discriminant Analysis (50 pts)\n",
    "\n",
    "LDA finds a **linear** combination of features that separates two or more classes or labels.\n",
    "\n",
    "### 2a: Import `LinearDiscriminantAnalysis` (15 pts)\n",
    "\n",
    "Import the `sklearn.discriminant_analysis.LinearDiscriminantAnalysis` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p2-1",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert LinearDiscriminantAnalysis.__init__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 2b: LDA transformation (15 pts)\n",
    "\n",
    "Come up with `X_lda` which is a matrix of transformed features from `X_mnist` using LDA. Do not change any parameter settings of the `LinearDiscriminantAnalysis` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_mnist, y_mnist)\n",
    "X_lda = lda.transform(X_mnist)\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p2-2",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert X_lda.shape[1] == 9\n",
    "assert np.isclose(X_lda[0].sum(), -8.929053278244288)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 2c: Apply k-Means (10 pts)\n",
    "\n",
    "Apply k-means clustering with `KMeans(n_clusters=10, random_state=42)` to `X_lda`. Report the clustering result as `y_kmeans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# Start your code here\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters = 10, random_state = 42)\n",
    "y_kmeans = kmeans.fit_predict(X_lda)\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "p2-3",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.bincount(y_kmeans)[0] == 189\n",
    "assert np.bincount(y_kmeans)[-1] == 174"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 2d: Assigning labels (10 pts)\n",
    "\n",
    "Define a function `assign_labels` that assigns a label to each cluster by using the most common label from the cluster. This step converts the clustering to a classification prediction. If the label **9** is most common in the cluster 1, all points belonging to that cluster should be labeled as 9. `assign_labels` takes the following arguments:\n",
    "\n",
    "- y: the original labels (numpy array, default: `y_mnist`)\n",
    "- y_hat: the clustering result (numpy array, default: `y_kmeans`)\n",
    "\n",
    "This function should return a numpy array `y_predict` in which a label is assigned to each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_labels(y = y_mnist, y_hat = y_kmeans):\n",
    "########################################\n",
    "# Start your code here\n",
    "    y_predict = np.zeros(y.shape, dtype = 'int')\n",
    "    \n",
    "    for i in range(10):\n",
    "        collect_label = y[y_hat == i]\n",
    "        count_label = np.bincount(collect_label)\n",
    "        common_label = np.argmax(count_label)\n",
    "        \n",
    "        y_predict[y_hat == i] = common_label\n",
    "########################################\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p2-4",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "y_predict = assign_labels()\n",
    "\n",
    "assert np.bincount(y_predict)[1] == 189\n",
    "assert np.bincount(y_predict)[4] == 175"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.7]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
